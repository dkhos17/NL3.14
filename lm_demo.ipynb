{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lm_demo.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"GWc_zjBuN_Cm"},"source":["**Project NL3.14**"]},{"cell_type":"code","metadata":{"id":"Hgd3B7sKk0-r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611335799354,"user_tz":-240,"elapsed":1813,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}},"outputId":"f90e56c7-e2b7-43b6-e178-fb7299bf5f79"},"source":["# Mount to Google Drive \r\n","from google.colab import drive\r\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WWh228yOk5SF","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1611335799356,"user_tz":-240,"elapsed":1808,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}},"outputId":"8876d664-dcf9-4d02-97a4-753e3a2c1fb9"},"source":["# Imports We need in the project\r\n","import os\r\n","import re\r\n","import torch\r\n","import glob\r\n","import string\r\n","import math\r\n","import random\r\n","from termcolor import colored\r\n","import torch\r\n","import torch.nn as nn\r\n","import pandas as pd\r\n","import numpy as np\r\n","import zipfile\r\n","import seaborn as sbr\r\n","import matplotlib.pyplot as plt \r\n","import pandas as pd\r\n","import functools\r\n","from tqdm import tqdm\r\n","from sklearn.decomposition import PCA\r\n","from sklearn.model_selection import train_test_split\r\n","from gensim.models import Word2Vec\r\n","import enum \r\n","from copy import copy, deepcopy\r\n","\r\n","SEED = 147\r\n","torch.manual_seed(SEED)\r\n","torch.__version__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.7.0+cu101'"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"SMW3ZzrvzKqY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611335804794,"user_tz":-240,"elapsed":7239,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}},"outputId":"1d1d0656-d222-47d5-c9a5-357386eb8fcb"},"source":["!pip install --upgrade pip\r\n","!pip install transformers\r\n","\r\n","from transformers import BertTokenizer, BertModel, AutoTokenizer, AdamW, BertForMaskedLM"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (20.3.3)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from transformers) (3.3.0)\n","Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->transformers) (3.4.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gEeQ7ZiWbhU0","executionInfo":{"status":"ok","timestamp":1611335804795,"user_tz":-240,"elapsed":7234,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}},"outputId":"5f45cc2f-32c5-43d6-edfe-05b0b76cdb09"},"source":["# create GPU(cuda) device \r\n","torch.cuda.empty_cache()\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","device"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"fwdBgmCPXVpa"},"source":["**Let's see how the model works**"]},{"cell_type":"code","metadata":{"id":"J07nr70somOh"},"source":["# helper class to parse and tokenize georgian data\r\n","class GeoData:\r\n","    def __init__(self, text):\r\n","     self.txt = text\r\n","     self.sentences = []\r\n","\r\n","     self.alphabet = self.get_geoalphabet()\r\n","     self.alphabet.extend(self.get_arabian_nums())\r\n","     self.alphabet.extend(self.get_romanian_nums())\r\n","     self.alphabet.extend(self.get_optional_symbols()) \r\n","     # create pattern with our alphabet for regex\r\n","     self.pattern = re.compile(r\"^[\" + ''.join(self.alphabet) + r\"]+$\")\r\n","     # train data\r\n","     self.__process__()\r\n","\r\n","    def get_alphabet(self):\r\n","      return self.alphabet\r\n","\r\n","    def get_geoalphabet(self):\r\n","      alphabet = ['ა', 'ბ', 'გ', 'დ', 'ე', 'ვ', 'ზ', 'თ', 'ი', 'კ', 'ლ', 'მ', 'ნ', 'ო', 'პ', 'ჟ', 'რ', 'ს', 'ტ', 'უ', 'ფ', 'ქ', 'ღ', 'ყ', 'შ', 'ჩ', 'ც', 'ძ', 'წ', 'ჭ', 'ხ', 'ჯ', 'ჰ']\r\n","      assert len(set(alphabet)) == 33\r\n","      return alphabet \r\n","\r\n","    def get_arabian_nums(self):\r\n","      return ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\r\n","    \r\n","    def get_romanian_nums(self):\r\n","      return ['X', 'I', 'V', 'L', 'C', 'D', 'M']\r\n","\r\n","    def get_optional_symbols(self):\r\n","      return ['-']\r\n","\r\n","    def get_badsymbols(self):\r\n","     return ['\\n', '\\t', '_', '+', '=', '*', '&', '%', '$', '#', '@', '^', '/', '~', '„', ',,', '”', '“']\r\n","\r\n","    def get_punctuation(self):\r\n","      return ['.', ';', '!', '?', ',', ':']\r\n","\r\n","    def get_endofsentence(self):\r\n","      return ['»', '«', '[', ']', '{', '}', '(', ')', '...']\r\n","\r\n","    def get_sentences(self):\r\n","      return self.sentences\r\n","\r\n","    def configure_word(self, w):\r\n","      w = w.strip() # remove extra white spaces\r\n","      if len(w) == 0: return False, ''\r\n","      if w.count('-') > 1: return False, '.' # check count of '-' to avoid bad words\r\n","      if w == '-' or w[0] == '-': return True, '' + w[1:] # check if word is start of dialog\r\n","      if len(w) > 15: return False, '.' # check word length to avoid coruptted words\r\n","      if (w not in self.get_alphabet() and self.pattern.match(w)) or w in [',', ':']: # because of regex syntax, check custom if words is good for our alphabet\r\n","        if w[len(w)-1] == '‐' or w[len(w)-1] == '-': # note - these two chars are different!\r\n","          return True, w[:len(w)-1] # remove no need char\r\n","        return True, w + ' ' # add white space for next word\r\n","      return False, '.' # fix end of sentence\r\n","                      \r\n","    def __process__(self):\r\n","      # clean from bad symbols\r\n","      for dl in self.get_badsymbols():\r\n","        self.txt = self.txt.replace(dl, ' ')\r\n","\r\n","      # fix end of sentences and replace them with '.'\r\n","      for sw in self.get_endofsentence():\r\n","        self.txt = self.txt.replace(sw, '.')\r\n","\r\n","      # split punctuation from words\r\n","      for pn in self.get_punctuation():\r\n","        self.txt = self.txt.replace(pn, ' ' + pn + ' ')\r\n","      \r\n","      # remove extra white spaces\r\n","      self.txt = re.sub(r'\\s+', ' ', self.txt).strip()\r\n","\r\n","      # build sentences\r\n","      sentence, length = '', 0\r\n","      for w in self.txt.split(' '):\r\n","          is_word, word = self.configure_word(w)\r\n","          \r\n","          if is_word or word in ['.', ';', '!', '?']:\r\n","            sentence, length = sentence + word, length + (1 if len(word) > 1 else 0)\r\n","\r\n","          if not is_word or word in ['.', ';', '!', '?']:\r\n","            if length >= 2: self.sentences.append(sentence.strip())\r\n","            sentence, length = '', 0\r\n","      if length >= 2: self.sentences.append(sentence.strip())\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DyVamn48AqJX","executionInfo":{"status":"ok","timestamp":1611335804795,"user_tz":-240,"elapsed":7224,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}},"outputId":"64d08397-a2e9-4d49-e36d-230e9b5e22c9"},"source":["# Helper Class to test the model\r\n","class TestData:\r\n","  def __init__(self, text):\r\n","    self.sentences = GeoData(text).get_sentences()\r\n","\r\n","  def add_data(self, text):\r\n","    self.sentences.extend(GeoData(text).get_sentences())\r\n","\r\n","  def reset_data(self):\r\n","    self.sentences = []\r\n","  \r\n","  def get_testset(self):\r\n","    return [sentence.split(' ') for sentence in self.sentences]\r\n","\r\n","#### usage ###\r\n","TEST = TestData('დატასეტის შექმნა და მისი მეთოდები: ედ დატა, რესეტ დატა და გეთ ტესტსეტ.')\r\n","TEST.add_data('ეს წინადადება დაემატა')\r\n","for t in TEST.get_testset():\r\n","  print(t)\r\n","print('\\n')\r\n","\r\n","TEST.reset_data()\r\n","TEST.add_data('წინა დატა წაიშალა და ახლა მხოლოდ ეს წინადადება დარჩება')\r\n","for t in TEST.get_testset():\r\n","  print(t)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['დატასეტის', 'შექმნა', 'და', 'მისი', 'მეთოდები', ':', 'ედ', 'დატა', ',', 'რესეტ', 'დატა', 'და', 'გეთ', 'ტესტსეტ', '.']\n","['ეს', 'წინადადება', 'დაემატა']\n","\n","\n","['წინა', 'დატა', 'წაიშალა', 'და', 'ახლა', 'მხოლოდ', 'ეს', 'წინადადება', 'დარჩება']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ztxRgdlmPp_U"},"source":["# Test sentences to predict the rest of sentences with given model\r\n","sent = ['ასეთი ლამაზი ადგილი ჩემს სიცოცხლეში არსად', \r\n","        'მე მინდა ,', \r\n","        '', \r\n","        'კაროჩე ესეთი ამბავია , რომ', \r\n","        'ეს პატარა საქართველო',\r\n","        'იმიტომ',\r\n","        'ასეა თუ ისე',\r\n","        'ასეა',\r\n","        'სანამ სიკეთეა ამ ქვეყანაზედ ,',\r\n","        'აქ დიდი არჩევანი იყო ,']\r\n","\r\n","to_predict = [i.split(' ') for i in sent]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ReD5iyvUa5ai"},"source":["# load word2vec from the drive\r\n","from gensim.test.utils import get_tmpfile\r\n","fname = get_tmpfile(\"/content/gdrive/My Drive/NL3.14/resources/word2vec.model\")\r\n","w2v = Word2Vec.load(fname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u6AOc74AydmT"},"source":["embed_dim = 300\r\n","max_seq_len = 10\r\n","vocab_size = w2v.wv.vectors.shape[0]\r\n","batch_size = 64"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pTIx6GiFk61B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611335809325,"user_tz":-240,"elapsed":11737,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}},"outputId":"d6bdf3e4-6e6e-4ad0-cd14-ae4be66669cd"},"source":["# Base Line Model\r\n","class NGramLM(nn.Module):\r\n","    def __init__(self, vocab_size, embedding_dim, context_size):\r\n","        super(NGramLM, self).__init__()\r\n","        self.embeddings = nn.Embedding.from_pretrained(torch.tensor(w2v.wv.vectors), padding_idx=0)\r\n","        self.linear1 = nn.Linear(context_size * embedding_dim, 500)\r\n","        self.linear2 = nn.Linear(500, vocab_size)\r\n","\r\n","    def forward(self, inputs):\r\n","        embeds = self.embeddings(inputs).view((1, -1))\r\n","        out = nn.functional.relu(self.linear1(embeds))\r\n","        out = self.linear2(out)\r\n","        \r\n","        return out\r\n","\r\n","baseline_model = NGramLM(vocab_size, 300, 10).to(device)\r\n","baseline_model.load_state_dict(torch.load('/content/gdrive/My Drive/NL3.14/resources/baseline_model'))\r\n","baseline_model\r\n","\r\n","# load the model from drive\r\n","class PredictionModel(nn.Module):\r\n","    def __init__(self, emb_dim, hid_dim, vocab_size):\r\n","        super().__init__()\r\n","        \r\n","        self.hidden_dim = hid_dim\r\n","        self.emb_dim = embed_dim\r\n","        self.embedding = nn.Embedding.from_pretrained(torch.tensor(w2v.wv.vectors), padding_idx=0)\r\n","        self.lstm = nn.LSTM(self.emb_dim, self.hidden_dim, dropout=0.2, num_layers=2, bidirectional=True, batch_first=True)\r\n","        self.classifier = nn.Linear(4 * hid_dim, vocab_size)\r\n","              \r\n","    def forward(self, src):\r\n","        embedded = self.embedding(src)\r\n","        _, (hidden1, _) = self.lstm(embedded)\r\n","        hidden1 = torch.cat((hidden1[0], hidden1[1], hidden1[2], hidden1[3]), dim=1)\r\n","        return self.classifier(hidden1)\r\n","        \r\n","pred_model = PredictionModel(embed_dim, 128, vocab_size).to(device)\r\n","pred_model.load_state_dict(torch.load('/content/gdrive/My Drive/NL3.14/resources/prediction_model'))\r\n","pred_model\r\n","\r\n","# tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\r\n","# model = BertForMaskedLM.from_pretrained('bert-base-multilingual-cased').to(device)\r\n","# model.load_state_dict(torch.load('/content/gdrive/My Drive/NL3.14/resources/bert_model'))\r\n","# model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PredictionModel(\n","  (embedding): Embedding(145271, 300, padding_idx=0)\n","  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n","  (classifier): Linear(in_features=512, out_features=145271, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"2Rpu3CbnO_BE"},"source":["class BertDatasetTest(torch.utils.data.Dataset):\r\n","  def __init__(self, txts):\r\n","        self.txts = txts\r\n","\r\n","  def __len__(self):\r\n","        return len(self.txts)\r\n","\r\n","  def __getitem__(self, index):\r\n","        sentence = self.txts[index]\r\n","        sentence.append('[MASK]')\r\n","        sentence = sentence[-max_seq_len:]\r\n","        embedX = tokenizer(' '.join(sentence),  padding='max_length', return_tensors='pt', max_length=max_seq_len, truncation=True)\r\n","        return embedX['input_ids'].to(device),embedX['token_type_ids'].to(device), embedX['attention_mask'].to(device)\r\n","\r\n","class PredictionDatasetTest(torch.utils.data.Dataset):\r\n","  def __init__(self, x):\r\n","        self.x = x\r\n","\r\n","  def __len__(self):\r\n","        return len(self.x)\r\n","\r\n","  def __getitem__(self, index):\r\n","        def toEmbed(word):\r\n","          try:\r\n","            return w2v.wv.vocab[word].index\r\n","          except:\r\n","            try:\r\n","              return w2v.wv.vocab[w2v.wv.most_similar(word)[0][0]].index\r\n","            except:\r\n","              return random.randint(0, len(w2v.wv.vectors) - 1)\r\n","        x = [toEmbed(i) for i in self.x[index][-max_seq_len:]]\r\n","        x = (x + [0]*max_seq_len)[:max_seq_len]\r\n","        return torch.LongTensor(x).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B-lIX-9s0XVd"},"source":["class Model(enum.Enum):\r\n","   Bert = 1\r\n","   Prediction = 2\r\n","   Baseline = 3\r\n","\r\n","def BeamSearchModification(model, softmax, sentence, k, deep=4):\r\n","  Q = [(sentence, 0.0, 0)]\r\n","  punkt = [w2v.wv.vocab[i].index for i in ['.',  ',', ':']]\r\n","  eps = 10.0\r\n","  \r\n","  while Q:\r\n","    sent, prob, length = Q.pop(0)\r\n","    if length == deep: break\r\n","    topk = torch.topk(model(sent.unsqueeze(0)), dim=1, k=k)\r\n","    for i, v in zip(topk.indices.cpu().detach().numpy()[0], topk.values.cpu().detach().numpy()[0]):\r\n","      if i == sent[-1] or i in sent: continue\r\n","      if sent[-1] in punkt and i in punkt: \r\n","        sent[-1] = i\r\n","        Q.append((sent, prob + eps * v, length))\r\n","      else:\r\n","        Q.append((torch.cat((sent, torch.tensor([i]).to(device))), prob + eps * v, length+1))\r\n","    eps -= 0.2\r\n","  return sorted(Q, key= lambda t : t[1])[0][0].cpu().detach().numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NmEac9OVdqYv"},"source":["# display the predicted words wuth diff. color\r\n","def visualize_prediction(idx, sentence, prediction):\r\n","    sentence = ' '.join(sentence).strip()\r\n","    for pn in ['.', ';', '!', '?', ',', ':']:\r\n","        sentence = sentence.replace(' ' + pn, pn)\r\n","\r\n","    prediction = ' '.join(prediction).strip()\r\n","    for pn in ['.', ';', '!', '?', ',', ':']:\r\n","        prediction = prediction.replace(' ' + pn, pn)\r\n","    \r\n","    print(colored((str(idx)+'). ' + sentence), attrs=['bold']), colored(prediction, 'magenta', attrs=['bold']))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xMrikUvGinJq"},"source":["test_params = {'batch_size': batch_size,\r\n","          'shuffle': False\r\n","}\r\n","\r\n","baseline_params = {'batch_size': 1,\r\n","          'shuffle': False\r\n","}\r\n","\r\n","def generate(model_type, model, to_predict, n_words):\r\n","  # Set the model in evalulation mode\r\n","  model.eval()\r\n","  \r\n","  # Define the softmax function\r\n","  softmax = nn.Softmax(dim=1)\r\n","  sequences = deepcopy(to_predict)\r\n","  predicted = []\r\n","\r\n","  with torch.no_grad():\r\n","    # if model_type == Model.Bert:\r\n","    #   for _ in range(n_words):\r\n","    #     bert_test_set = BertDatasetTest(sequences)\r\n","    #     bert_test_generator = torch.utils.data.DataLoader(bert_test_set, **test_params)\r\n","    #     for x_input_ids, x_token_type_ids, x_attention_mask in bert_test_generator:\r\n","    #       output = model(input_ids=x_input_ids.squeeze(1),\r\n","    #                   token_type_ids=x_token_type_ids.squeeze(1),\r\n","    #                   attention_mask=x_attention_mask.squeeze(1),\r\n","    #                 )\r\n","    #       # It is applied the softmax function to the predicted tensor\r\n","    #       prediction = softmax(output.logits)[:,-1,:]\r\n","          \r\n","    #       # It is taken the idx with the highest probability\r\n","    #       arg_max = torch.argmax(prediction, dim=1)\r\n","          \r\n","    #       # The prediction tensor is transformed into a numpy array\r\n","    #       arg_max = arg_max.cpu().detach().numpy()\r\n","\r\n","    #       token = tokenizer.convert_ids_to_tokens(arg_max)\r\n","    #       print(token)\r\n","\r\n","    #       full_prediction += token\r\n","    #       for f, s in zip(sequences, full_prediction):\r\n","    #         f[-1] = s\r\n","    # else:\r\n","    if model_type == Model.Baseline:\r\n","      for i in range(n_words):\r\n","        next_test_set = PredictionDatasetTest(sequences)\r\n","        next_test_generator = torch.utils.data.DataLoader(next_test_set, **baseline_params)\r\n","        preds = []\r\n","        for x in next_test_generator:\r\n","          output = baseline_model(x)\r\n","          prediction = softmax(output)\r\n","          # print(prediction.shape)\r\n","          arg_max = torch.topk(prediction.squeeze(0), dim=0, k=5).indices.cpu().detach().numpy()\r\n","          # print(arg_max)\r\n","          pred = w2v.wv.index2word[np.random.choice(arg_max)]\r\n","          preds.append(pred)\r\n","        for f, s in zip(sequences, preds):\r\n","          f.append(s)\r\n","      for f, s in zip(to_predict, sequences):\r\n","        predicted.append((f, s[len(f):]))\r\n","    else:\r\n","      for i in [4] * (n_words // 4) + ([n_words % 4] if n_words % 4 != 0 else []):\r\n","        next_test_set = PredictionDatasetTest(sequences)\r\n","        next_test_generator = torch.utils.data.DataLoader(next_test_set, **test_params)\r\n","        for x in next_test_generator:\r\n","          arg_max = []\r\n","          for _, sentence in enumerate(x):\r\n","            sentence = sentence.cpu().detach().numpy()\r\n","            arg_max.append(BeamSearchModification(pred_model, softmax, torch.tensor(sentence[sentence != 0]).to(device), 7, i))\r\n","          \r\n","          preds = [[w2v.wv.index2word[word] for word in i] for i in arg_max]\r\n","          \r\n","          for f, s in zip(sequences, preds):\r\n","            f.extend(s[-4:])\r\n","      for f, s in zip(to_predict, sequences):\r\n","        predicted.append((f, s[len(f):]))\r\n","    \r\n","  print(\"Prediction: \\n\")\r\n","  for i, s in enumerate(predicted):\r\n","    visualize_prediction(i+1, s[0], s[1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cX1GlQp5JMrE"},"source":["**Enter number of words you want to predict**"]},{"cell_type":"code","metadata":{"id":"ypjt-Y-_JHFX"},"source":["num_words_to_predict = 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ljJ02HhqH1A2"},"source":["**Baseline model prediction**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L2mys-HnH0TM","executionInfo":{"status":"ok","timestamp":1611336234000,"user_tz":-240,"elapsed":800,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}},"outputId":"f8f4b90b-903a-43d6-b42e-ed55707d058e"},"source":["TEST.reset_data()\r\n","for i in sent:\r\n","  TEST.add_data(i)\r\n","generate(Model.Baseline, baseline_model, TEST.get_testset(), num_words_to_predict)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Prediction: \n","\n","\u001b[1m1). ასეთი ლამაზი ადგილი ჩემს სიცოცხლეში არსად\u001b[0m \u001b[1m\u001b[35mარის ეს ეს მაგრამ ეს მაგრამ:: რაც რაც\u001b[0m\n","\u001b[1m2). მე მინდა,\u001b[0m \u001b[1m\u001b[35mეს რა არის ეს ეს უნდა:: არის ეს\u001b[0m\n","\u001b[1m3). კაროჩე ესეთი ამბავია, რომ\u001b[0m \u001b[1m\u001b[35mრა რა უნდა არის არ მაგრამ მაგრამ რაც მე ის\u001b[0m\n","\u001b[1m4). ეს პატარა საქართველო\u001b[0m \u001b[1m\u001b[35mმაგრამ მაგრამ მაგრამ უნდა არის ეს: არ ეს რაც\u001b[0m\n","\u001b[1m5). ასეა თუ ისე\u001b[0m \u001b[1m\u001b[35mუნდა მაგრამ არის: მაგრამ: არის უნდა ეს უნდა\u001b[0m\n","\u001b[1m6). სანამ სიკეთეა ამ ქვეყანაზედ,\u001b[0m \u001b[1m\u001b[35mმაგრამ ეს მაგრამ::: მაგრამ მაგრამ არ უნდა\u001b[0m\n","\u001b[1m7). აქ დიდი არჩევანი იყო,\u001b[0m \u001b[1m\u001b[35mეს ეს არის მაგრამ რაც უნდა რაც: არ არის\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7lfSjp7DH7-S"},"source":["**LSTM model prediction**"]},{"cell_type":"code","metadata":{"id":"pp_iB7UA3Ruw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611335831998,"user_tz":-240,"elapsed":34392,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}},"outputId":"2b6283db-0a34-4315-9788-ee625974df5a"},"source":["TEST.reset_data()\r\n","for i in sent:\r\n","  TEST.add_data(i)\r\n","generate(Model.Prediction, pred_model, TEST.get_testset(), num_words_to_predict)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Prediction: \n","\n","\u001b[1m1). ასეთი ლამაზი ადგილი ჩემს სიცოცხლეში არსად\u001b[0m \u001b[1m\u001b[35mჰქონდა მისთვის საკმარისი იყო მისი კარის მიმართ: მიმართ: გული სწორედ\u001b[0m\n","\u001b[1m2). მე მინდა,\u001b[0m \u001b[1m\u001b[35mახლა შემიძლია თქვენი გაბედნიერება ჩემი კეკლუცობა დედის მიმართ დედის მიმართ ქალი აყვანა\u001b[0m\n","\u001b[1m3). კაროჩე ესეთი ამბავია, რომ\u001b[0m \u001b[1m\u001b[35mიქცა. ივან ფიოდოროვიჩის დარღვევა მივიჩნიოთ ეწერა: ეწერა: ხომ იმ\u001b[0m\n","\u001b[1m4). ეს პატარა საქართველო\u001b[0m \u001b[1m\u001b[35mიქცა გახდა მეორე ს-ის ერთ-ერთი საუკეთესო მათგანი იყო მათგანი იყო მთავარი მომხრე\u001b[0m\n","\u001b[1m5). ასეა თუ ისე\u001b[0m \u001b[1m\u001b[35mუპასუხა მოხუცმა იმ კილოთი განაგრძო მის კითხვა: კითხვა. მინდა ვიცოდე\u001b[0m\n","\u001b[1m6). სანამ სიკეთეა ამ ქვეყანაზედ,\u001b[0m \u001b[1m\u001b[35mითხოვს სამართლიანობას შეკრებაა და ის ბოროტება არ ჩავიდინო არ ჩავიდინო მათ ყოველნაირი\u001b[0m\n","\u001b[1m7). აქ დიდი არჩევანი იყო,\u001b[0m \u001b[1m\u001b[35mუნდა დატოვებული არჩევანია: იმ ადამიანთა რიცხვს რომ რიცხვს რომ ოდენ რომელთა\u001b[0m\n"],"name":"stdout"}]}]}