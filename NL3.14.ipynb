{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"NL3.14.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"204131218c094daab028755b0a1f6086":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4c16337d9a554b76b089d8adbd9d7eb0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c791969f6e9b4dfaaf0276f3d01208ed","IPY_MODEL_8b62652e12a44abca7dcda0f06438e79"]}},"4c16337d9a554b76b089d8adbd9d7eb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c791969f6e9b4dfaaf0276f3d01208ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_805d2aacdca44e73acae75911b8fe5e1","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_867e78027c954b2cb227d004f87b9203"}},"8b62652e12a44abca7dcda0f06438e79":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_61a069c4255248ba9b44959a7e523253","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:01&lt;00:00, 512B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d8795a351aa14c6a97654967c8d16035"}},"805d2aacdca44e73acae75911b8fe5e1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"867e78027c954b2cb227d004f87b9203":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"61a069c4255248ba9b44959a7e523253":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d8795a351aa14c6a97654967c8d16035":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"32947360490647c39b4a63a8a916b8aa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f7fa2b9f59974fb6864b3f62ef0c153d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_01f3d3025bc4401096b7d57cbf391f2a","IPY_MODEL_501fecf7e06d4d4eaf2f800ade812bd1"]}},"f7fa2b9f59974fb6864b3f62ef0c153d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"01f3d3025bc4401096b7d57cbf391f2a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a60cf61333a94afba2629404b1c10e0d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":995526,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":995526,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_02a26ce46ad84524a77830535608a97e"}},"501fecf7e06d4d4eaf2f800ade812bd1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fa9f1c5c83164b399e2b5f9bc78680e9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 996k/996k [01:34&lt;00:00, 10.6kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_22e391af98324c3d9e072c7f785cd5e7"}},"a60cf61333a94afba2629404b1c10e0d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"02a26ce46ad84524a77830535608a97e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fa9f1c5c83164b399e2b5f9bc78680e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"22e391af98324c3d9e072c7f785cd5e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d695e83b9a4949f0a75caf37a4a7f612":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7d6c8a547768425a8d5d751b872787e5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_50f7179d709d4613b93a6049b7ceac71","IPY_MODEL_f3df743115f64b3082cc8dbeaccd5f35"]}},"7d6c8a547768425a8d5d751b872787e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"50f7179d709d4613b93a6049b7ceac71":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_18c46ebc90854c499fb821e6df4d0915","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1961828,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1961828,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7bd8afc817ac47c381ba2a4ac04d5d35"}},"f3df743115f64b3082cc8dbeaccd5f35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_57145154dd9448aca321e54abaaeed39","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.96M/1.96M [00:03&lt;00:00, 560kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c9ae85905edd476c94e8cfc89d4d0c6e"}},"18c46ebc90854c499fb821e6df4d0915":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7bd8afc817ac47c381ba2a4ac04d5d35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"57145154dd9448aca321e54abaaeed39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c9ae85905edd476c94e8cfc89d4d0c6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"455f395fa0fd483d8f18542ee7df918d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_29bbf80714ef4c8db5578952aad3a0e5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_cb01fc8c75f34e2f8951d441ff95139f","IPY_MODEL_717170f375944930b1e93c49cb1e26fc"]}},"29bbf80714ef4c8db5578952aad3a0e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cb01fc8c75f34e2f8951d441ff95139f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6979b2d97a424e29987a7ae6cbc25250","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":714314041,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":714314041,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_49ba4679e95c4618a0c7e58039f882e6"}},"717170f375944930b1e93c49cb1e26fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3ef361a72b1f447bbb04de9d9c9d1aba","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 714M/714M [01:29&lt;00:00, 8.01MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_86c5ee9a03764eb7b3e4f99d73aef852"}},"6979b2d97a424e29987a7ae6cbc25250":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"49ba4679e95c4618a0c7e58039f882e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3ef361a72b1f447bbb04de9d9c9d1aba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"86c5ee9a03764eb7b3e4f99d73aef852":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"L0y_56y-3zqi"},"source":["**Project NL3.14**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-FhIIZyj4v4-","executionInfo":{"status":"ok","timestamp":1611331878879,"user_tz":-240,"elapsed":14793,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}},"outputId":"e26c683c-253e-4a58-bd5e-49cb5c2fbcbe"},"source":["# Mount to Google Drive \r\n","from google.colab import drive\r\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"1-JKIMU00I-r","executionInfo":{"status":"ok","timestamp":1611331883043,"user_tz":-240,"elapsed":8002,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}},"outputId":"c2f3f1da-1f03-4ba0-c7a3-c564a49fc40d"},"source":["# Imports We need in the project\r\n","import os\r\n","import re\r\n","import torch\r\n","import glob\r\n","import string\r\n","import math\r\n","import random\r\n","import pickle\r\n","import torch\r\n","import torch.nn as nn\r\n","import pandas as pd\r\n","import numpy as np\r\n","import zipfile\r\n","import seaborn as sbr\r\n","import matplotlib.pyplot as plt \r\n","import pandas as pd\r\n","import functools\r\n","from datetime import datetime\r\n","from tqdm import tqdm\r\n","from sklearn.decomposition import PCA\r\n","from sklearn.model_selection import train_test_split\r\n","import ast\r\n","\r\n","SEED = 147\r\n","torch.manual_seed(SEED)\r\n","torch.__version__"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.7.0+cu101'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tgMLAOolGS8Y","executionInfo":{"status":"ok","timestamp":1611331892555,"user_tz":-240,"elapsed":16113,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}},"outputId":"43e6aa1b-fc22-4be5-b3f0-999efeefc273"},"source":["!pip install --upgrade pip\r\n","!pip install transformers\r\n","from transformers import BertTokenizer, BertModel, AutoTokenizer, AdamW, BertForMaskedLM"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting pip\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/eb/4a3642e971f404d69d4f6fa3885559d67562801b99d7592487f1ecc4e017/pip-20.3.3-py2.py3-none-any.whl (1.5MB)\n","\r\u001b[K     |▏                               | 10kB 25.6MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 31.1MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 28.5MB/s eta 0:00:01\r\u001b[K     |▉                               | 40kB 32.5MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 29.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61kB 32.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71kB 19.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81kB 21.3MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 20.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 102kB 20.8MB/s eta 0:00:01\r\u001b[K     |██▍                             | 112kB 20.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 122kB 20.8MB/s eta 0:00:01\r\u001b[K     |██▉                             | 133kB 20.8MB/s eta 0:00:01\r\u001b[K     |███                             | 143kB 20.8MB/s eta 0:00:01\r\u001b[K     |███▎                            | 153kB 20.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 163kB 20.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 174kB 20.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 184kB 20.8MB/s eta 0:00:01\r\u001b[K     |████                            | 194kB 20.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 204kB 20.8MB/s eta 0:00:01\r\u001b[K     |████▌                           | 215kB 20.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 225kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 235kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 245kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 256kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 266kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 276kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 286kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 296kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 307kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 317kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 327kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 337kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 348kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 358kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 368kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 378kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 389kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 399kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 409kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 419kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 430kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 440kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 450kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 460kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 471kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 481kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 491kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 501kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 512kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 522kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 532kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 542kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 552kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 563kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 573kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 583kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 593kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 604kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 614kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 624kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 634kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 645kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 655kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 665kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 675kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 686kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 696kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 706kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 716kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 727kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 737kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 747kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 757kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 768kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 778kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 788kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 798kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 808kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 819kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 829kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 839kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 849kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 860kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 870kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 880kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 890kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 901kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 911kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 921kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 931kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 942kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 952kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 962kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 972kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 983kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 993kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.0MB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.0MB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.0MB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.0MB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0MB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.1MB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.1MB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.1MB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.1MB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1MB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.1MB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.1MB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.1MB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.1MB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.2MB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.2MB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.2MB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2MB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.2MB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.2MB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.2MB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.2MB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.2MB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.3MB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.3MB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3MB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.3MB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.3MB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.3MB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.3MB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.3MB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.4MB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.4MB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.4MB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4MB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.4MB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.4MB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.4MB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.4MB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.4MB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.5MB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.5MB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5MB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.5MB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.5MB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.5MB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.5MB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 20.8MB/s \n","\u001b[?25hInstalling collected packages: pip\n","  Found existing installation: pip 19.3.1\n","    Uninstalling pip-19.3.1:\n","      Successfully uninstalled pip-19.3.1\n","Successfully installed pip-20.3.3\n","Collecting transformers\n","  Downloading transformers-4.2.2-py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 17.7 MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from transformers) (3.3.0)\n","Collecting tokenizers==0.9.4\n","  Downloading tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 76.3 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->transformers) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n","\u001b[K     |████████████████████████████████| 883 kB 71.3 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893258 sha256=f92d8a4115a1580d4e1db2b553c34080fa4f9e54566425cff05e9d17102b1b70\n","  Stored in directory: /root/.cache/pip/wheels/49/25/98/cdea9c79b2d9a22ccc59540b1784b67f06b633378e97f58da2\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D1qjh3xHIMmR","executionInfo":{"status":"ok","timestamp":1611331892556,"user_tz":-240,"elapsed":14550,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}},"outputId":"50e7e2bc-401a-4998-99d0-a0d09694c625"},"source":["# create GPU(cuda) device \r\n","torch.cuda.empty_cache()\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","device"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"f-ZYEYq04J_u"},"source":["**LOAD ALREADY CONFIGURED DATA**"]},{"cell_type":"code","metadata":{"id":"xbNWkU2g1ree","executionInfo":{"status":"ok","timestamp":1611331905337,"user_tz":-240,"elapsed":26120,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}}},"source":["from gensim.models import Word2Vec\r\n","from gensim.test.utils import get_tmpfile\r\n","\r\n","# load trained word2vec from drive \r\n","fname = get_tmpfile(\"/content/gdrive/My Drive/NL3.14/resources/word2vec.model\")\r\n","w2v = Word2Vec.load(fname)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"MfVHAvhh0MyI","executionInfo":{"status":"ok","timestamp":1611331911522,"user_tz":-240,"elapsed":30348,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}}},"source":["# read configured csv files from drive\r\n","total_df = pd.read_csv(\"/content/gdrive/My Drive/NL3.14/resources/geosentences.csv\")\r\n","final_df = pd.read_csv(\"/content/gdrive/My Drive/NL3.14/resources/train.csv\")"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"y42_k0Rf0Oe6","executionInfo":{"status":"ok","timestamp":1611331912259,"user_tz":-240,"elapsed":30050,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}}},"source":["# split the given data as for train, as for validation.\r\n","bert_train, bert_validation = train_test_split(total_df, test_size=0.05)\r\n","train, validation_test = train_test_split(final_df, test_size=0.05)\r\n","validation, test = train_test_split(validation_test, test_size=0.05)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"dB5dqi_U5AUJ","executionInfo":{"status":"ok","timestamp":1611331912262,"user_tz":-240,"elapsed":29181,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}},"outputId":"74653b66-4e86-4cdd-bf34-9d3135eb392b"},"source":["train.head()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>x</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>103473</th>\n","      <td>['კი', 'არ', 'გამარტყამს']</td>\n","      <td>ახლა</td>\n","    </tr>\n","    <tr>\n","      <th>1042978</th>\n","      <td>['არც', 'კი', 'ამიხსნა', ',', 'რას']</td>\n","      <td>გულისხმობდა</td>\n","    </tr>\n","    <tr>\n","      <th>141033</th>\n","      <td>[',', 'თითქოს', 'სადაცაა']</td>\n","      <td>სულს</td>\n","    </tr>\n","    <tr>\n","      <th>695754</th>\n","      <td>['ისინი', 'მიმართავენ', 'ჩვეულებრივ', 'მკურნალ...</td>\n","      <td>ეს</td>\n","    </tr>\n","    <tr>\n","      <th>885723</th>\n","      <td>['თუ', 'რამდენად', 'მოსწონდა', 'ან', 'არ', 'მო...</td>\n","      <td>სტუმრის</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                         x            y\n","103473                          ['კი', 'არ', 'გამარტყამს']         ახლა\n","1042978               ['არც', 'კი', 'ამიხსნა', ',', 'რას']  გულისხმობდა\n","141033                          [',', 'თითქოს', 'სადაცაა']         სულს\n","695754   ['ისინი', 'მიმართავენ', 'ჩვეულებრივ', 'მკურნალ...           ეს\n","885723   ['თუ', 'რამდენად', 'მოსწონდა', 'ან', 'არ', 'მო...      სტუმრის"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"ZP6sXoa4FnYz","executionInfo":{"status":"ok","timestamp":1611331912264,"user_tz":-240,"elapsed":28223,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}}},"source":["# set up dimensions\r\n","embed_dim = 300\r\n","vocab_size = w2v.wv.vectors.shape[0]\r\n","max_seq_len = 10\r\n","batch_size = 32"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"c-jNPjrTUTM1","executionInfo":{"status":"ok","timestamp":1611331912264,"user_tz":-240,"elapsed":26159,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}}},"source":["# Helper Class for BertModel\r\n","class DatasetTrain(torch.utils.data.Dataset):\r\n","  def __init__(self, txts):\r\n","        self.txts = txts\r\n","\r\n","  def __len__(self):\r\n","        return len(self.txts)\r\n","\r\n","  def __getitem__(self, index):\r\n","        sentence = self.txts[index]\r\n","        splits = sentence.split(' ')\r\n","        chosenWords = random.choices(splits, k = len(splits) // 10 + 1)\r\n","        for idx, word in enumerate(splits):\r\n","          if word in chosenWords:\r\n","            splits[idx] = '[MASK]'\r\n","        embedX = tokenizer(' '.join(splits),  padding='max_length', return_tensors='pt', max_length=max_seq_len, truncation=True)\r\n","        embedY = tokenizer(sentence, padding='max_length', return_tensors='pt', max_length=max_seq_len, truncation=True)\r\n","        return embedX['input_ids'].to(device),embedX['token_type_ids'].to(device), embedX['attention_mask'].to(device), embedY['input_ids'].to(device)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DvvcKF1iVDmi","executionInfo":{"status":"ok","timestamp":1611331912265,"user_tz":-240,"elapsed":24684,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}}},"source":["# Parameters\r\n","train_params = {'batch_size': batch_size,\r\n","          'shuffle': True\r\n","         }\r\n","val_params = {'batch_size': batch_size\r\n","         }\r\n","\r\n","# Dataloaders for train, validation and test\r\n","bert_training_set = DatasetTrain(bert_train['sentences'].tolist())\r\n","bert_training_generator = torch.utils.data.DataLoader(bert_training_set, **train_params)\r\n","\r\n","bert_validation_set = DatasetTrain(bert_validation['sentences'].tolist())\r\n","bert_validation_generator = torch.utils.data.DataLoader(bert_validation_set, **val_params)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264,"referenced_widgets":["204131218c094daab028755b0a1f6086","4c16337d9a554b76b089d8adbd9d7eb0","c791969f6e9b4dfaaf0276f3d01208ed","8b62652e12a44abca7dcda0f06438e79","805d2aacdca44e73acae75911b8fe5e1","867e78027c954b2cb227d004f87b9203","61a069c4255248ba9b44959a7e523253","d8795a351aa14c6a97654967c8d16035","32947360490647c39b4a63a8a916b8aa","f7fa2b9f59974fb6864b3f62ef0c153d","01f3d3025bc4401096b7d57cbf391f2a","501fecf7e06d4d4eaf2f800ade812bd1","a60cf61333a94afba2629404b1c10e0d","02a26ce46ad84524a77830535608a97e","fa9f1c5c83164b399e2b5f9bc78680e9","22e391af98324c3d9e072c7f785cd5e7","d695e83b9a4949f0a75caf37a4a7f612","7d6c8a547768425a8d5d751b872787e5","50f7179d709d4613b93a6049b7ceac71","f3df743115f64b3082cc8dbeaccd5f35","18c46ebc90854c499fb821e6df4d0915","7bd8afc817ac47c381ba2a4ac04d5d35","57145154dd9448aca321e54abaaeed39","c9ae85905edd476c94e8cfc89d4d0c6e","455f395fa0fd483d8f18542ee7df918d","29bbf80714ef4c8db5578952aad3a0e5","cb01fc8c75f34e2f8951d441ff95139f","717170f375944930b1e93c49cb1e26fc","6979b2d97a424e29987a7ae6cbc25250","49ba4679e95c4618a0c7e58039f882e6","3ef361a72b1f447bbb04de9d9c9d1aba","86c5ee9a03764eb7b3e4f99d73aef852"]},"id":"aselDcQ_bsVO","executionInfo":{"status":"ok","timestamp":1611325885241,"user_tz":-240,"elapsed":55547,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}},"outputId":"8007d163-5c97-4a2d-f7c9-3fe72b4f3f71"},"source":["# load multilingual bert pre-trained model and tokenizer\r\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\r\n","model = BertForMaskedLM.from_pretrained('bert-base-multilingual-cased').to(device)\r\n","model.load_state_dict(torch.load('/content/gdrive/My Drive/NL3.14/resources/bert_model'))\r\n","optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\r\n","\r\n","#Calculate loss on validation data\r\n","def bert_valid_loss(model, dl):\r\n","  #Switch model to evaluation mode and then back to train\r\n","  model.eval()\r\n","  with torch.no_grad(): # tells Pytorch not to store values of intermediate computations for backward pass because we not gonna need gradients.\r\n","    loss = 0\r\n","    batches = math.ceil(len(dl) / batch_size)\r\n","    for x_input_ids, x_token_type_ids, x_attention_mask, y_input_ids in bert_validation_generator:\r\n","        output = model(input_ids=x_input_ids.squeeze(1),\r\n","                     token_type_ids=x_token_type_ids.squeeze(1),\r\n","                     attention_mask=x_attention_mask.squeeze(1),\r\n","                     labels=y_input_ids,\r\n","                    )\r\n","        loss += output.loss.item()\r\n","  model.train()\r\n","  return loss / batches"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"204131218c094daab028755b0a1f6086","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"32947360490647c39b4a63a8a916b8aa","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d695e83b9a4949f0a75caf37a4a7f612","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1961828.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"455f395fa0fd483d8f18542ee7df918d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714314041.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"m8M_C2Ieb_5z"},"source":["from datetime import datetime\r\n","# Switch model to train mode\r\n","model.train()\r\n","\r\n","validation_loss = None\r\n","for epoch in range(1, 2):\r\n","    epoch_loss = 0\r\n","    epoch_acc = 0\r\n","    epoch_f_score = 0\r\n","    batches = math.ceil(len(train) / batch_size)\r\n","    print(batches, \"batches\")\r\n","    t = datetime.now()\r\n","    i = 0\r\n","    for x_input_ids, x_token_type_ids, x_attention_mask, y_input_ids in bert_training_generator:\r\n","        optimizer.zero_grad()\r\n","        #forward\r\n","        # Model calculates loss and also outputs classification scores, which need to go through softmax later\r\n","        output = model(input_ids=x_input_ids.squeeze(1),\r\n","                     token_type_ids=x_token_type_ids.squeeze(1),\r\n","                     attention_mask=x_attention_mask.squeeze(1),\r\n","                     labels=y_input_ids,\r\n","                    )\r\n","\r\n","        #Back propagation\r\n","        output.loss.backward()\r\n","        \r\n","        #Gradient step\r\n","        optimizer.step()\r\n","\r\n","        epoch_loss += output.loss.item()\r\n","        \r\n","        if (i + 1) % 1000 == 0:\r\n","            print(datetime.now() - t)\r\n","            dev_loss = bert_valid_loss(model, bert_validation)\r\n","            if validation_loss is None or validation_loss > dev_loss:\r\n","                validation_loss = dev_loss\r\n","                # Save best model\r\n","                torch.save(model.state_dict(), '/content/gdrive/My Drive/NL3.14/resources/bert_model') \r\n","            print(f'Epoch {epoch} batch {i} | Avg Train Loss: {epoch_loss/(i + 1):.6f} | Current Dev Loss {dev_loss:.6f} | Minimal Dev Loss {validation_loss:.6f}')\r\n","        i+=1\r\n","    print(f'Epoch {epoch} | Avg Train Loss: {epoch_loss/batches:.6f} ')  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7IOfdqKlycIH","executionInfo":{"status":"ok","timestamp":1611331929106,"user_tz":-240,"elapsed":16832,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}}},"source":["batch_size = 256\r\n","train_params = {'batch_size': batch_size,\r\n","          'shuffle': True\r\n","}\r\n","# Helper Class For LstmModel\r\n","class PredictionDatasetTrain(torch.utils.data.Dataset):\r\n","  def __init__(self, x, y):\r\n","        self.x = x\r\n","        self.y = y\r\n","\r\n","  def __len__(self):\r\n","        return len(self.y)\r\n","\r\n","  def __getitem__(self, index):\r\n","        def toEmbed(word):\r\n","          try:\r\n","            return w2v.wv.vocab[word].index\r\n","          except:\r\n","            try:\r\n","              return w2v.wv.vocab[w2v.wv.most_similar(word)[0][0]].index\r\n","            except:\r\n","              return random.randint(0, len(w2v.wv.vectors) - 1)\r\n","        x = [toEmbed(i) for i in self.x[index]]\r\n","        x = (x + [0]*max_seq_len)[:max_seq_len]\r\n","        y = torch.LongTensor([w2v.wv.vocab[self.y[index]].index])\r\n","        return torch.LongTensor(x).to(device), y.to(device)\r\n","\r\n","# Dataloaders for train, validation\r\n","trainX = [ast.literal_eval(i) for i in train['x'].tolist()]\r\n","validX = [ast.literal_eval(i) for i in validation['x'].tolist()]\r\n","testX = [ast.literal_eval(i) for i in test['x'].tolist()]\r\n","\r\n","next_training_set = PredictionDatasetTrain(trainX, train['y'].tolist())\r\n","next_training_generator = torch.utils.data.DataLoader(next_training_set, **train_params)\r\n","\r\n","next_validation_set = PredictionDatasetTrain(validX, validation['y'].tolist())\r\n","next_validation_generator = torch.utils.data.DataLoader(next_validation_set, **train_params)\r\n","\r\n","test_set = PredictionDatasetTrain(testX, test['y'].tolist())\r\n","test_set_generator = torch.utils.data.DataLoader(test_set, **train_params)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AHSE2PT9uNRt","executionInfo":{"status":"ok","timestamp":1611331945459,"user_tz":-240,"elapsed":33178,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}},"outputId":"f6ec1019-f2ca-4abc-b491-39cc0efc6543"},"source":["class PredictionModel(nn.Module):\r\n","    def __init__(self, emb_dim, hid_dim, vocab_size):\r\n","        super().__init__()\r\n","        \r\n","        self.hidden_dim = hid_dim\r\n","        self.emb_dim = embed_dim\r\n","        self.embedding = nn.Embedding.from_pretrained(torch.tensor(w2v.wv.vectors), padding_idx=0)\r\n","\r\n","        self.lstm = nn.LSTM(self.emb_dim, self.hidden_dim, dropout=0.2, num_layers=2, bidirectional=True, batch_first=True)\r\n","       \r\n","        self.classifier = nn.Linear(4 * hid_dim, vocab_size)\r\n","              \r\n","    def forward(self, src):\r\n","        embedded = self.embedding(src)\r\n","        _, (hidden1, _) = self.lstm(embedded)\r\n","        hidden1 = torch.cat((hidden1[0], hidden1[1], hidden1[2], hidden1[3]), dim=1)\r\n","        return self.classifier(hidden1)\r\n","    \r\n","    def persistEmbedWeights(self):\r\n","      #we wanted but ver vqenit\r\n","      pickle.dump( self.embedding.weight.cpu().detach().numpy(), open(\"/content/gdrive/My Drive/NL3.14/resources/finedEmbeds.data\", \"wb\" ))  \r\n","\r\n","pred_model = PredictionModel(embed_dim, 128, vocab_size).to(device)\r\n","pred_model.load_state_dict(torch.load('/content/gdrive/My Drive/NL3.14/resources/prediction_model'))\r\n","pred_model"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PredictionModel(\n","  (embedding): Embedding(145271, 300, padding_idx=0)\n","  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n","  (classifier): Linear(in_features=512, out_features=145271, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"TZJZGDJUOiUj","executionInfo":{"status":"ok","timestamp":1611331945459,"user_tz":-240,"elapsed":33172,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}}},"source":["criterion = nn.CrossEntropyLoss(ignore_index=0).to(device)\r\n","optimizer = AdamW(pred_model.parameters(), lr=1e-3, eps=1e-7)\r\n","lr_scheduler =  torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5, min_lr=1e-9)\r\n","\r\n","#Calculate loss on validation data\r\n","def valid_loss(model, dl, generator):\r\n","  #Switch model to evaluation mode and then back to train\r\n","  model.eval()\r\n","  loss = 0\r\n","  with torch.no_grad(): # tells Pytorch not to store values of intermediate computations for backward pass because we not gonna need gradients.\r\n","    batches = math.ceil(len(dl) / batch_size)\r\n","    for x, y in generator:\r\n","        preds = model(x)\r\n","        loss += criterion(preds.squeeze(0), y.squeeze(1)).item()\r\n","  model.train()\r\n","  return loss / batches"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Fy20Do2uQCb"},"source":["# Switch model to train mode\r\n","pred_model.train()\r\n","\r\n","validation_loss = None\r\n","for epoch in range(1, 10):\r\n","    batch_loss = 0\r\n","    epoch_acc = 0\r\n","    epoch_f_score = 0\r\n","    batches = math.ceil(len(train) / batch_size)\r\n","    print(batches, \"batches\")\r\n","    t = datetime.now()\r\n","    i = 0\r\n","    for x, y in next_training_generator:\r\n","        i+=1\r\n","        \r\n","        optimizer.zero_grad()\r\n","        #forward\r\n","        output = pred_model(x)\r\n","        \r\n","        loss = criterion(output.squeeze(0), y.squeeze(1))\r\n","\r\n","        #Back propagation\r\n","        loss.backward()\r\n","        \r\n","        #Gradient step\r\n","        optimizer.step()\r\n","\r\n","        batch_loss += loss.item()\r\n","        \r\n","        if i % 200 == 0:\r\n","            dev_loss = valid_loss(pred_model, validation, next_validation_generator)\r\n","            if validation_loss is None or validation_loss > dev_loss:\r\n","                validation_loss = dev_loss\r\n","                # Save best model\r\n","                torch.save(pred_model.state_dict(), '/content/gdrive/My Drive/NL3.14/resources/prediction_model') \r\n","\r\n","            lr_scheduler.step(validation_loss)\r\n","            curr_lr = [param_group['lr'] for param_group in optimizer.param_groups][0]\r\n","            print(f'Epoch {epoch} batch {i} | Batch Train Loss: {batch_loss/200:.6f} | Current validation Loss {dev_loss:.6f}| Minimal validation Loss {validation_loss:.6f} | Current Validation Perplexity {torch.exp(torch.tensor(dev_loss)):.6f} | Time passed {datetime.now() - t} | Current LR {curr_lr}')\r\n","            batch_loss = 0\r\n","\r\n","pred_model.persistEmbedWeights()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xve6NBPogyyp"},"source":["**LSTM Perplexity on test set**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Usp_za1gyGM","executionInfo":{"status":"ok","timestamp":1611331946246,"user_tz":-240,"elapsed":33254,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}},"outputId":"41a96a5d-6a24-4571-b71e-517c3653acf0"},"source":["print(f'LSTM Perplexity on test set : {torch.exp(torch.tensor(valid_loss(pred_model, test, test_set_generator)))}')"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Perplexity on test set: 1907.0517578125\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"71G573P5A7i7","executionInfo":{"status":"ok","timestamp":1611332948402,"user_tz":-240,"elapsed":1978,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}},"outputId":"242e6e3b-955f-4c8a-ec2c-86b77d0e2087"},"source":["batch_size = 1\r\n","\r\n","train_params = {'batch_size': batch_size,\r\n","          'shuffle': True\r\n","}\r\n","\r\n","next_training_set = PredictionDatasetTrain(trainX, train['y'].tolist())\r\n","next_training_generator = torch.utils.data.DataLoader(next_training_set, **train_params)\r\n","\r\n","next_validation_set = PredictionDatasetTrain(validX, validation['y'].tolist())\r\n","next_validation_generator = torch.utils.data.DataLoader(next_validation_set, **train_params)\r\n","\r\n","test_set = PredictionDatasetTrain(testX, test['y'].tolist())\r\n","test_set_generator = torch.utils.data.DataLoader(test_set, **train_params)\r\n","\r\n","# Base Line Model\r\n","class NGramLM(nn.Module):\r\n","    def __init__(self, vocab_size, embedding_dim, context_size):\r\n","        super(NGramLM, self).__init__()\r\n","        self.embeddings = nn.Embedding.from_pretrained(torch.tensor(w2v.wv.vectors), padding_idx=0)\r\n","        self.linear1 = nn.Linear(context_size * embedding_dim, 500)\r\n","        self.linear2 = nn.Linear(500, vocab_size)\r\n","\r\n","    def forward(self, inputs):\r\n","        embeds = self.embeddings(inputs).view((1, -1))\r\n","        out = nn.functional.relu(self.linear1(embeds))\r\n","        out = self.linear2(out)\r\n","        \r\n","        return out\r\n","\r\n","baseline_model = NGramLM(vocab_size, 300, 10).to(device)\r\n","baseline_model.load_state_dict(torch.load('/content/gdrive/My Drive/NL3.14/resources/baseline_model'))\r\n","baseline_model"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NGramLM(\n","  (embeddings): Embedding(145271, 300, padding_idx=0)\n","  (linear1): Linear(in_features=3000, out_features=500, bias=True)\n","  (linear2): Linear(in_features=500, out_features=145271, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"tNzD6B4QHLq5","executionInfo":{"status":"ok","timestamp":1611332984177,"user_tz":-240,"elapsed":598,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}}},"source":["criterion = nn.CrossEntropyLoss(ignore_index=0).to(device)\r\n","optimizer = AdamW(baseline_model.parameters(), lr=1e-3, eps=1e-7)\r\n","lr_scheduler =  torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5, min_lr=1e-9)\r\n","\r\n","\r\n","#Calculate loss on validation data\r\n","def ngram_valid_loss(model, dl, generator):\r\n","  #Switch model to evaluation mode and then back to train\r\n","  model.eval()\r\n","  loss = 0\r\n","  with torch.no_grad(): # tells Pytorch not to store values of intermediate computations for backward pass because we not gonna need gradients.\r\n","    batches = math.ceil(len(dl) / batch_size)\r\n","    for x, y in generator:\r\n","        preds = model(x)\r\n","        loss += criterion(preds, y.squeeze(1)).item()\r\n","  model.train()\r\n","  return loss / batches"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"NXOTEoSpCtTm"},"source":["# Switch model to train mode\r\n","baseline_model.train()\r\n","\r\n","validation_loss = None\r\n","for epoch in range(1, 50):\r\n","    batch_loss = 0\r\n","    epoch_acc = 0\r\n","    epoch_f_score = 0\r\n","    batches = math.ceil(len(train) / batch_size)\r\n","    print(batches, \"batches\")\r\n","    t = datetime.now()\r\n","    i = 0\r\n","    for x, y in next_training_generator:\r\n","        i+=1\r\n","        optimizer.zero_grad()\r\n","        output = baseline_model(x)\r\n","        loss = criterion(output, y.squeeze(1))\r\n","        loss.backward()\r\n","        optimizer.step()\r\n","        batch_loss += loss.item()\r\n","        \r\n","        if i % 50 == 0:\r\n","            dev_loss = ngram_valid_loss(baseline_model, validation, next_validation_generator)\r\n","            if validation_loss is None or validation_loss > dev_loss:\r\n","                validation_loss = dev_loss\r\n","                # Save best model\r\n","                torch.save(baseline_model.state_dict(), '/content/gdrive/My Drive/NL3.14/resources/baseline_model') \r\n","\r\n","            lr_scheduler.step(validation_loss)\r\n","            curr_lr = [param_group['lr'] for param_group in optimizer.param_groups][0]\r\n","            print(f'Epoch {epoch} batch {i} | Batch Train Loss: {batch_loss/50:.6f} | Current validation Loss {dev_loss:.6f}| Minimal validation Loss {validation_loss:.6f} | Current Validation Perplexity {torch.exp(torch.tensor(dev_loss)):.6f} | Time passed {datetime.now() - t} | Current LR {curr_lr}')\r\n","            batch_loss = 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7CC_VrJAOx1y"},"source":["**Linear Test Set Perplexity**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lrRnCg_m59xd","executionInfo":{"status":"ok","timestamp":1611333008414,"user_tz":-240,"elapsed":5596,"user":{"displayName":"aleksandre pertaia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicxAPRU7fxs5fj8SWVNaXL6_IoE7GyKrErz1Du=s64","userId":"07758201035277987049"}},"outputId":"3fd2762c-1352-4d75-cdb2-4dd9d092257f"},"source":["print(f'Linear Perplexity on test set : {torch.exp(torch.tensor(ngram_valid_loss(baseline_model, test, test_set_generator)))}')"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Linear Perplexity on test set : 211320.109375\n"],"name":"stdout"}]}]}